{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO66qXmydAJZlcAeUm8NPTn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pouria1380-creator/Deep_learning_ne/blob/main/image_classification_cnn_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72605c64"
      },
      "source": [
        "# Task\n",
        "Build a CNN model from scratch using PyTorch for image classification, train it on a real dataset, and evaluate its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11b4fcc0"
      },
      "source": [
        "## Import libraries\n",
        "\n",
        "### Subtask:\n",
        "Import the necessary PyTorch libraries (torch, torch.nn, torch.optim, torchvision).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ff98608"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary PyTorch libraries as requested by the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50395eb7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84dcebb7"
      },
      "source": [
        "## Define the cnn model\n",
        "\n",
        "### Subtask:\n",
        "Create a class that inherits from `torch.nn.Module` and define the convolutional layers, pooling layers, and fully connected layers for the CNN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc355b69"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the CNN class with convolutional, pooling, and fully connected layers, and the forward pass.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec7e4861",
        "outputId": "fa014aad-f40e-4376-f878-0cb5f7355609"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        # Calculate the input size for the first fully connected layer\n",
        "        # Assuming input image size is 32x32 (like CIFAR-10)\n",
        "        # After three max pooling layers with kernel_size 2 and stride 2,\n",
        "        # the spatial dimensions will be reduced by 2^3 = 8 times.\n",
        "        # So, 32x32 becomes 4x4. The number of channels is 128.\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = torch.flatten(x, 1) # Flatten the output for the fully connected layers\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "print(\"CNN class defined.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c549788d"
      },
      "source": [
        "## Load and preprocess data\n",
        "\n",
        "### Subtask:\n",
        "Load an image dataset (e.g., CIFAR-10 or MNIST) using `torchvision.datasets` and define data transformations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08e589dd"
      },
      "source": [
        "**Reasoning**:\n",
        "Define data transformations and load the CIFAR-10 dataset using torchvision.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6b8af91",
        "outputId": "2deca869-e5af-44ce-b0cf-a370e78baf93"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transformations\n",
        "# Convert PIL Image to Tensor and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize CIFAR-10 images\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 training dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Load CIFAR-10 test dataset\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "print(\"CIFAR-10 dataset loaded and transformations defined.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:11<00:00, 15.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 dataset loaded and transformations defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f391e91"
      },
      "source": [
        "## Create dataloaders\n",
        "\n",
        "### Subtask:\n",
        "Create `DataLoader` objects for training and testing data to handle batching and shuffling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87db934c"
      },
      "source": [
        "**Reasoning**:\n",
        "Create DataLoader objects for the training and testing datasets using the specified batch size and shuffling requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b05d405e",
        "outputId": "edab7db6-aaac-423a-e9fb-f1c3aba07fad"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create DataLoader for training dataset\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Create DataLoader for test dataset\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(\"DataLoaders created for training and testing.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders created for training and testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7766877f"
      },
      "source": [
        "## Define loss function and optimizer\n",
        "\n",
        "### Subtask:\n",
        "Choose an appropriate loss function (e.g., CrossEntropyLoss for classification) and an optimizer (e.g., Adam or SGD).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8da00e97"
      },
      "source": [
        "**Reasoning**:\n",
        "Instantiate the CrossEntropyLoss as the loss function and the Adam optimizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2168faed",
        "outputId": "812c412e-9a2b-446b-d742-e42c0bd93fc4"
      },
      "source": [
        "# Instantiate the model (assuming the CNN class is already defined from a previous step)\n",
        "model = CNN(num_classes=10) # Assuming 10 classes for CIFAR-10\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss function and optimizer defined.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function and optimizer defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca832524"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "### Subtask:\n",
        "Implement the training loop to iterate over epochs, calculate loss, perform backpropagation, and update weights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b346f98"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the training loop as described in the instructions, iterating through epochs and batches to perform forward and backward passes and update model weights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90cc9d86",
        "outputId": "e4403ffb-864b-42fb-e41c-5de8f7977f74"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{i + 1}/{len(trainloader)}], Loss: {running_loss / 100:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch [1/10], Batch [100/782], Loss: 1.9232\n",
            "Epoch [1/10], Batch [200/782], Loss: 1.5507\n",
            "Epoch [1/10], Batch [300/782], Loss: 1.4308\n",
            "Epoch [1/10], Batch [400/782], Loss: 1.3296\n",
            "Epoch [1/10], Batch [500/782], Loss: 1.2729\n",
            "Epoch [1/10], Batch [600/782], Loss: 1.1993\n",
            "Epoch [1/10], Batch [700/782], Loss: 1.1095\n",
            "Epoch [2/10], Batch [100/782], Loss: 0.9903\n",
            "Epoch [2/10], Batch [200/782], Loss: 0.9528\n",
            "Epoch [2/10], Batch [300/782], Loss: 0.9716\n",
            "Epoch [2/10], Batch [400/782], Loss: 0.9166\n",
            "Epoch [2/10], Batch [500/782], Loss: 0.9057\n",
            "Epoch [2/10], Batch [600/782], Loss: 0.8815\n",
            "Epoch [2/10], Batch [700/782], Loss: 0.8538\n",
            "Epoch [3/10], Batch [100/782], Loss: 0.7480\n",
            "Epoch [3/10], Batch [200/782], Loss: 0.7224\n",
            "Epoch [3/10], Batch [300/782], Loss: 0.7296\n",
            "Epoch [3/10], Batch [400/782], Loss: 0.7095\n",
            "Epoch [3/10], Batch [500/782], Loss: 0.7183\n",
            "Epoch [3/10], Batch [600/782], Loss: 0.7037\n",
            "Epoch [3/10], Batch [700/782], Loss: 0.7344\n",
            "Epoch [4/10], Batch [100/782], Loss: 0.5937\n",
            "Epoch [4/10], Batch [200/782], Loss: 0.5757\n",
            "Epoch [4/10], Batch [300/782], Loss: 0.5926\n",
            "Epoch [4/10], Batch [400/782], Loss: 0.5770\n",
            "Epoch [4/10], Batch [500/782], Loss: 0.5792\n",
            "Epoch [4/10], Batch [600/782], Loss: 0.6011\n",
            "Epoch [4/10], Batch [700/782], Loss: 0.6115\n",
            "Epoch [5/10], Batch [100/782], Loss: 0.4336\n",
            "Epoch [5/10], Batch [200/782], Loss: 0.4584\n",
            "Epoch [5/10], Batch [300/782], Loss: 0.4589\n",
            "Epoch [5/10], Batch [400/782], Loss: 0.4729\n",
            "Epoch [5/10], Batch [500/782], Loss: 0.4734\n",
            "Epoch [5/10], Batch [600/782], Loss: 0.4740\n",
            "Epoch [5/10], Batch [700/782], Loss: 0.4878\n",
            "Epoch [6/10], Batch [100/782], Loss: 0.3239\n",
            "Epoch [6/10], Batch [200/782], Loss: 0.3289\n",
            "Epoch [6/10], Batch [300/782], Loss: 0.3576\n",
            "Epoch [6/10], Batch [400/782], Loss: 0.3626\n",
            "Epoch [6/10], Batch [500/782], Loss: 0.3489\n",
            "Epoch [6/10], Batch [600/782], Loss: 0.3810\n",
            "Epoch [6/10], Batch [700/782], Loss: 0.3883\n",
            "Epoch [7/10], Batch [100/782], Loss: 0.2301\n",
            "Epoch [7/10], Batch [200/782], Loss: 0.2326\n",
            "Epoch [7/10], Batch [300/782], Loss: 0.2467\n",
            "Epoch [7/10], Batch [400/782], Loss: 0.2637\n",
            "Epoch [7/10], Batch [500/782], Loss: 0.2580\n",
            "Epoch [7/10], Batch [600/782], Loss: 0.2806\n",
            "Epoch [7/10], Batch [700/782], Loss: 0.2884\n",
            "Epoch [8/10], Batch [100/782], Loss: 0.1675\n",
            "Epoch [8/10], Batch [200/782], Loss: 0.1380\n",
            "Epoch [8/10], Batch [300/782], Loss: 0.1447\n",
            "Epoch [8/10], Batch [400/782], Loss: 0.1860\n",
            "Epoch [8/10], Batch [500/782], Loss: 0.2041\n",
            "Epoch [8/10], Batch [600/782], Loss: 0.2135\n",
            "Epoch [8/10], Batch [700/782], Loss: 0.2290\n",
            "Epoch [9/10], Batch [100/782], Loss: 0.0989\n",
            "Epoch [9/10], Batch [200/782], Loss: 0.0996\n",
            "Epoch [9/10], Batch [300/782], Loss: 0.1052\n",
            "Epoch [9/10], Batch [400/782], Loss: 0.1282\n",
            "Epoch [9/10], Batch [500/782], Loss: 0.1338\n",
            "Epoch [9/10], Batch [600/782], Loss: 0.1400\n",
            "Epoch [9/10], Batch [700/782], Loss: 0.1745\n",
            "Epoch [10/10], Batch [100/782], Loss: 0.0894\n",
            "Epoch [10/10], Batch [200/782], Loss: 0.0823\n",
            "Epoch [10/10], Batch [300/782], Loss: 0.0873\n",
            "Epoch [10/10], Batch [400/782], Loss: 0.1024\n",
            "Epoch [10/10], Batch [500/782], Loss: 0.1102\n",
            "Epoch [10/10], Batch [600/782], Loss: 0.1288\n",
            "Epoch [10/10], Batch [700/782], Loss: 0.1584\n",
            "Finished Training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d92aa27b"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "### Subtask:\n",
        "Implement the evaluation loop to calculate the model's performance on the test set (e.g., accuracy).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ec793c8"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the evaluation loop to calculate the model's performance on the test set, including setting the model to evaluation mode, disabling gradient calculation, iterating through the test data, making predictions, and calculating accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "451ef79a",
        "outputId": "a5d3a3ed-350f-427c-ee11-bb677a84e5ce"
      },
      "source": [
        "# Implement the evaluation loop\n",
        "print(\"\\nStarting evaluation...\")\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct_predictions / total_samples\n",
        "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')\n",
        "\n",
        "print(\"Finished Evaluation.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation...\n",
            "Accuracy of the network on the 10000 test images: 74.93 %\n",
            "Finished Evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4268175"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   A Convolutional Neural Network (CNN) model was successfully defined using PyTorch, including convolutional, pooling, and fully connected layers.\n",
        "*   The CIFAR-10 dataset was loaded and preprocessed with normalization.\n",
        "*   DataLoaders were created for both training and testing datasets with a batch size of 64.\n",
        "*   The CrossEntropyLoss was selected as the loss function, and the Adam optimizer with a learning rate of 0.001 was used.\n",
        "*   The model was trained for 10 epochs, with the training loss decreasing over time.\n",
        "*   The final trained model achieved an accuracy of 74.93% on the 10000 test images.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The model's performance is reasonable but could potentially be improved by hyperparameter tuning (learning rate, batch size, number of epochs) or architectural changes (adding more layers, using different kernel sizes).\n",
        "*   Further analysis could involve examining misclassified images to understand the model's weaknesses or implementing techniques like data augmentation to improve generalization.\n"
      ]
    }
  ]
}